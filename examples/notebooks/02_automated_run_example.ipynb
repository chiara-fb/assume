{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run simulation using configuration and input files\n",
    "\n",
    "Welcome to the second tutorial in the ASSUME framework series. In the previous tutorial, we learned how to manually set up and execute simulations. However, for larger simulations involving multiple agents and demand series, it's more efficient to automate the process using configuration files and input files. This tutorial will guide you through the steps of creating these files and using them to run simulations in ASSUME.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you begin, make sure you have completed the first tutorial, which covers the basics of setting up and running a simple simulation manually. You should also have the ASSUME framework installed on your system.\n",
    "\n",
    "## Tutorial outline:\n",
    "\n",
    "- Introduction \n",
    "- [Setting up the environment](#setting-up-the-environment)\n",
    "- [Creating input files](#creating-input-files)\n",
    "    - [Power plant units](#power-plant-units)\n",
    "    - [Fuel prices](#fuel-prices)\n",
    "    - [Demand units](#demand-units)\n",
    "    - [Demand time series](#demand-time-series)\n",
    "- [Creating a configuration file](#creating-a-configuration-file)\n",
    "- [Running the simulation](#running-the-simulation)\n",
    "- [Adjusting market configuration](#adjusting-market-configuration)\n",
    "- [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just install the ASSUME core package via pip. The instructions for an installation can be found here: https://assume.readthedocs.io/en/latest/installation.html.\n",
    "\n",
    "This step is only required if you are working with this notebook in collab. If you are working locally and you have installed the assume package, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "# Check whether notebook is run in google colab\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install assume-framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First things first, let's import the necessary packages and set up our working directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'types' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# import the main World class and the load_scenario_folder functions from assume\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m World\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscenario\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloader_csv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_scenario_folder\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Set up logging\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\assume-repo\\assume\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-FileCopyrightText: ASSUME Developers\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: AGPL-3.0-or-later\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarketConfig, MarketProduct\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscenario\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloader_csv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     load_custom_units,\n\u001b[32m     10\u001b[39m     load_scenario_folder,\n\u001b[32m     11\u001b[39m     run_learning,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworld\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m World\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\assume-repo\\assume\\common\\__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-FileCopyrightText: ASSUME Developers\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: AGPL-3.0-or-later\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mforecasts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Forecaster\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmango_serializer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mango_codec_factory\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmarket_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarketConfig, MarketProduct, Orderbook\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\assume-repo\\assume\\common\\forecasts.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01massume\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfast_pandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastIndex, FastSeries\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mForecaster\u001b[39;00m:\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    Forecaster represents a base class for forecasters based on existing files,\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    random noise, or actual forecast methods. It initializes with the provided index. It includes methods\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\assume-repo\\assume\\common\\fast_pandas.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_datetime64_any_dtype\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mth\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     15\u001b[39m     th = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\c.fusarbassini\\Desktop\\assume-repo\\.venv\\Lib\\site-packages\\torch\\__init__.py:2150\u001b[39m\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2145\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2146\u001b[39m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[32m   2147\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2148\u001b[39m \n\u001b[32m   2149\u001b[39m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2150\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2151\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m   2153\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2154\u001b[39m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[32m   2155\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\c.fusarbassini\\Desktop\\assume-repo\\.venv\\Lib\\site-packages\\torch\\functional.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, TYPE_CHECKING, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\c.fusarbassini\\Desktop\\assume-repo\\.venv\\Lib\\site-packages\\torch\\nn\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[32m      4\u001b[39m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[32m      5\u001b[39m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[32m      6\u001b[39m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[32m     11\u001b[39m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\c.fusarbassini\\Desktop\\assume-repo\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bilinear, Identity, LazyLinear, Linear  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     CELU,\n\u001b[32m      5\u001b[39m     ELU,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     Threshold,\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\c.fusarbassini\\Desktop\\assume-repo\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceLikeType\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Buffer, Parameter\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackwardHook, RemovableHandle\n\u001b[32m     21\u001b[39m __all__ = [\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_pre_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\c.fusarbassini\\Desktop\\assume-repo\\.venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:298\u001b[39m\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    297\u001b[39m \u001b[38;5;66;03m# Subtypes which have __tensor_flatten__ and __tensor_unflatten__.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTensorWithFlatten\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mProtocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__tensor_flatten__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\c.fusarbassini\\Desktop\\assume-repo\\.venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:339\u001b[39m, in \u001b[36mTensorWithFlatten\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdim\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    334\u001b[39m     ...\n\u001b[32m    336\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\n\u001b[32m    338\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     dtype: \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtypes\u001b[49m._dtype,\n\u001b[32m    340\u001b[39m     non_blocking: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    341\u001b[39m     copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    342\u001b[39m     *,\n\u001b[32m    343\u001b[39m     memory_format: Optional[torch.memory_format] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    344\u001b[39m ) -> torch.Tensor:\n\u001b[32m    345\u001b[39m     ...\n\u001b[32m    347\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m     memory_format: Optional[torch.memory_format] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    356\u001b[39m ) -> torch.Tensor:\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torch' has no attribute 'types' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# import the main World class and the load_scenario_folder functions from assume\n",
    "from assume import World\n",
    "from assume.scenario.loader_csv import load_scenario_folder\n",
    "\n",
    "# Set up logging\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths for input and output data\n",
    "csv_path = \"outputs\"\n",
    "input_path = \"inputs/example_01\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(\"local_db\", exist_ok=True)\n",
    "os.makedirs(input_path, exist_ok=True)\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Input Files\n",
    "\n",
    "### Power Plant Units\n",
    "\n",
    "In this section, we will create an input file that contains the details of our power plant units. Each power plant unit is represented by a set of attributes that define its operational and economic characteristics. The data is organized into a structured format that can be easily read and processed by the ASSUME framework.\n",
    "\n",
    "Once we have defined our data, we convert it into a pandas DataFrame. This is a convenient format for handling tabular data in Python and allows for easy manipulation and analysis. Finally, we save this DataFrame to a CSV file, which will serve as an input file for our simulation.\n",
    "\n",
    "Users can also create CSV files directly and save them to the input directory. This approach serves purely for demonstration purposes. Users can also adjust the input files manually to suit their needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data\n",
    "powerplant_units_data = {\n",
    "    \"name\": [\"Unit 1\", \"Unit 2\", \"Unit 3\", \"Unit 4\"],\n",
    "    \"technology\": [\"nuclear\", \"lignite\", \"hard coal\", \"combined cycle gas turbine\"],\n",
    "    \"bidding_EOM\": [\"naive_eom\", \"naive_eom\", \"naive_eom\", \"naive_eom\"],\n",
    "    \"fuel_type\": [\"uranium\", \"lignite\", \"hard coal\", \"natural gas\"],\n",
    "    \"emission_factor\": [0.0, 0.4, 0.3, 0.2],\n",
    "    \"max_power\": [1000.0, 1000.0, 1000.0, 1000.0],\n",
    "    \"min_power\": [200.0, 200.0, 200.0, 200.0],\n",
    "    \"efficiency\": [0.3, 0.5, 0.4, 0.6],\n",
    "    \"additional_cost\": [10.3, 1.65, 1.3, 3.5],\n",
    "    \"unit_operator\": [\"Operator 1\", \"Operator 2\", \"Operator 3\", \"Operator 4\"],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "powerplant_units_df = pd.DataFrame(powerplant_units_data)\n",
    "powerplant_units_df.to_csv(f\"{input_path}/powerplant_units.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a breakdown of each attribute we are including in our dataset:\n",
    "\n",
    "- `name`: A list of unique identifiers for each power plant unit. These names are used to reference the units throughout the simulation.\n",
    "\n",
    "- `technology`: The type of technology each unit uses to generate electricity.\n",
    "\n",
    "- `bidding_EOM`: The strategy that each power plant unit will use when bidding into the Energy Only Market. In this example, all units are using a `naive` strategy, which bids at the marginal cost of production. If there are two markets in your simulation, for example a capacity market for reserves, you can also specify a `bidding_capacity` column, which will be used when bidding into the reserve market.\n",
    "\n",
    "- `fuel_type`: The primary fuel source used by each unit. This information is crucial as it relates to fuel costs and availability, as well as emissions.\n",
    "\n",
    "- `emission_factor`: A numerical value representing the amount of CO2 (or equivalent) emissions produced per unit of electricity generated.\n",
    "\n",
    "- `max_power`: The maximum power output each unit can deliver. This is the upper limit of the unit's operational capacity given in MW.\n",
    "\n",
    "- `min_power`: The minimum stable level of power that each unit can produce while remaining operational. It is given in MW\n",
    "\n",
    "- `efficiency`: A measure of how effectively each unit converts fuel into electricity. This efficienty represent the final efficiency of converting fuel into electricity.\n",
    "\n",
    "- `additional_cost`: The additional operational costs for each unit, such as maintenance and staffing, expressed in EUR/MWh.\n",
    "\n",
    "- `unit_operator`: The entity responsible for operating each power plant unit. This could be a utility company, a private operator, or another type of organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel Prices\n",
    "\n",
    "Now, we will create a DataFrame for fuel prices and save it as a CSV file. In this case we are using constant values for fuel prices, but users can also define time series for fuel prices. This is useful for simulating scenarios where fuel prices are volatile and change over time.\n",
    "\n",
    "The framework automatically recognizes if fuel prices are constant or time-varying. If fuel prices are time-varying, the correct price will be used for each time step in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data\n",
    "fuel_prices_data = {\n",
    "    \"fuel\": [\"uranium\", \"lignite\", \"hard coal\", \"natural gas\", \"oil\", \"biomass\", \"co2\"],\n",
    "    \"price\": [1, 2, 10, 25, 40, 20, 25],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "fuel_prices_df = pd.DataFrame(fuel_prices_data).T\n",
    "fuel_prices_df.to_csv(f\"{input_path}/fuel_prices_df.csv\", index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand Units\n",
    "\n",
    "We also need to define the demand units for our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data\n",
    "demand_units_data = {\n",
    "    \"name\": [\"demand_EOM\"],\n",
    "    \"technology\": [\"inflex_demand\"],\n",
    "    \"bidding_EOM\": [\"naive_eom\"],\n",
    "    \"max_power\": [1000000],\n",
    "    \"min_power\": [0],\n",
    "    \"unit_operator\": [\"eom_de\"],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "demand_units_df = pd.DataFrame(demand_units_data)\n",
    "demand_units_df.to_csv(f\"{input_path}/demand_units.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what each attribute in our dataset represents:\n",
    "\n",
    "- `name`: This is the identifier for the demand unit. In our case, we have a single demand unit named `demand_EOM`, which could represent the total electricity demand of an entire market or a specific region within the market.\n",
    "\n",
    "- `technology`: Indicates the type of demand. Here, `inflex_demand` is used to denote inelastic demand, meaning that the demand does not change in response to price fluctuations within the short term. This is a typical assumption for electricity markets within a short time horizon.\n",
    "\n",
    "- `bidding_EOM`: Specifies the bidding strategy for the demand unit. Even though demand is typically price-inelastic in the short term, it still needs to be represented in the market. The `naive` strategy here bids the demand value into the market at a price of 3000 EUR/MWh.\n",
    "\n",
    "- `max_power`: The maximum power that the demand unit can request. In this example, we've set it to 1,000,000 MW, which is a placeholder. This value can be used for more sophisticated bidding strategies.\n",
    "\n",
    "- `min_power`: The minimum power level that the demand unit can request. In this case it also serves as a placeholder for more sophisticated bidding strategies.\n",
    "\n",
    "- `unit_operator`: The entity responsible for the demand unit. In this example, `eom_de` could represent an electricity market operator in Germany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand Time Series\n",
    "\n",
    "Lastly, we'll create a time series for the demand. \n",
    "\n",
    "You might notice, that the column name we use is demand_EOM, which is similar to the name of our demand unit. The framework is designed in such way, that multiple demand units can be defined in the same file. The column name is used to match the demand time series with the correct demand unit. Afterwards, each demand unit following a naive bidding strategy will bid the respective demand value into the market.\n",
    "\n",
    "Also, the length of the demand time series must be at least as long as the simulation time horizon. If the time series is longer than the simulation time horizon, the framework will automatically truncate it to the correct length. This is being demonstrated by giving date ranges of eight days that will be truncated to a week. If the resolution of the time series is higher than the simulation time step, the framework will automatically resample the time series to match the simulation time step. If it is shorter, an error will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a datetime index for a week with hourly resolution\n",
    "date_range = pd.date_range(start=\"2021-03-01\", periods=8 * 24, freq=\"h\")\n",
    "\n",
    "# Generate random demand values around 2000\n",
    "demand_values = np.random.normal(loc=2000, scale=200, size=8 * 24)\n",
    "\n",
    "# Create a DataFrame for the demand profile and save as CSV\n",
    "demand_profile = pd.DataFrame({\"datetime\": date_range, \"demand_EOM\": demand_values})\n",
    "demand_profile.to_csv(f\"{input_path}/demand_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Configuration File\n",
    "\n",
    "With our input files ready, we'll now create a configuration file that ASSUME will use to load the simulation. The config file allows easy customization of the simulation parameters, such as the simulation time horizon, the time step, and the market configuration. The configuration file is written in YAML format, which is a human-readable markup language that is commonly used for configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the config as a dictionary\n",
    "config_data = {\n",
    "    \"hourly_market\": {\n",
    "        \"start_date\": \"2021-03-01 00:00\",\n",
    "        \"end_date\": \"2021-03-07 00:00\",\n",
    "        \"time_step\": \"1h\",\n",
    "        \"save_frequency_hours\": 24,\n",
    "        \"markets_config\": {\n",
    "            \"EOM\": {\n",
    "                \"operator\": \"EOM_operator\",\n",
    "                \"product_type\": \"energy\",\n",
    "                \"opening_frequency\": \"1h\",\n",
    "                \"opening_duration\": \"1h\",\n",
    "                \"products\": [{\"duration\": \"1h\", \"count\": 1, \"first_delivery\": \"1h\"}],\n",
    "                \"volume_unit\": \"MWh\",\n",
    "                \"price_unit\": \"EUR/MWh\",\n",
    "                \"market_mechanism\": \"pay_as_clear\",\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the configuration as YAML\n",
    "with open(f\"{input_path}/config.yaml\", \"w\") as file:\n",
    "    yaml.dump(config_data, file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a breakdown of each key in our configuration file:\n",
    "\n",
    "- `start_date`: This key specifies the starting date and time for the market simulation. In this example, the simulation will start on March 1st, 2021, at midnight. The date and time are in the format \"YYYY-MM-DD HH:MM\".\n",
    "\n",
    "- `end_date`: This key defines the ending date and time for the market simulation, which is set to March 8th, 2021, at midnight. The simulation will run for one week.\n",
    "\n",
    "- `time_step`: This key defines the granularity of the market operation. Here, it is set to \"1h\", which means the simulation internal clock operates in one-hour intervals.\n",
    "\n",
    "- `save_frequency_hours`: This key indicates how often the simulation data should be saved. In this case, the data will be saved every 24 hours. This is helpful when you have a long simulation and want to observe the results at regular intervals (when using docker and database). Alternatively, you can remove this parameter to save all results at the end of the simulation.\n",
    "\n",
    "- `markets_config`: This key contains a nested dictionary with configurations for specific markets within the hourly market.\n",
    "\n",
    "  - `EOM`: This is a sub-key representing a specific market, named EOM.\n",
    "\n",
    "    - `operator`: This key specifies the operator of the EOM market, which is \"EOM_operator\" in this case.\n",
    "\n",
    "    - `product_type`: This key defines the type of product being traded in the market. Here, the product type is \"energy\".\n",
    "\n",
    "    - `opening_frequency`: This key indicates how often the market opens for trading. It is set to \"1h\", meaning the market opens every hour.\n",
    "\n",
    "    - `opening_duration`: This key specifies the duration for which the market is open during each trading session. It is also set to \"1h\".\n",
    "\n",
    "    - `products`: This key holds a list of products available for trading in the market. Each product is represented as a dictionary with its own set of configurations.\n",
    "\n",
    "      - `duration`: This key defines the delivery duration of the product, which is \"1h\" in this example.\n",
    "\n",
    "      - `count`: This key specifies the number of products available for each trading session. In this case, there is only one product per session.\n",
    "\n",
    "      - `first_delivery`: This key indicates the time until the first delivery of the product after trading. It is set to \"1h\" after the market closes.\n",
    "\n",
    "    - `volume_unit`: This key defines the unit of measurement for the volume of the product, which is \"MWh\" (megawatt-hour) in this example.\n",
    "\n",
    "    - `price_unit`: This key specifies the unit of measurement for the price of the product, which is \"EUR/MWh\" (Euros per megawatt-hour).\n",
    "\n",
    "    - `market_mechanism`: This key describes the market mechanism used to clear the market. \"pay_as_clear\" means that all participants pay the clearing price, which is the highest accepted bid price.\n",
    "\n",
    "To read more about available market configuration, please refer to https://assume.readthedocs.io/en/latest/market_config.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Simulation\n",
    "\n",
    "Now that we have our input files and configuration set up, we can run the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:Connected to the database\n",
      "INFO:assume.scenario.loader_csv:Input files path: inputs/example_01\n",
      "INFO:assume.scenario.loader_csv:Study case: hourly_market\n",
      "INFO:assume.scenario.loader_csv:Simulation ID: example_01_hourly_market\n",
      "INFO:assume.scenario.loader_csv:storage_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:exchange_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:industrial_dsm_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:residential_dsm_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:forecasts_df not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:exchanges_df not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:availability_df not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:buses not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:lines not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:save_frequency_hours is disabled due to CSV export being enabled. Data will be stored in the CSV files at the end of the simulation.\n",
      "INFO:assume.scenario.loader_csv:Adding markets\n",
      "INFO:assume.scenario.loader_csv:Read units from file\n",
      "INFO:assume.scenario.loader_csv:Adding power_plant units\n",
      "INFO:assume.scenario.loader_csv:Adding demand units\n",
      "INFO:assume.scenario.loader_csv:Adding unit operators and units\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "example_01_hourly_market 2021-03-06 23:00:00:  99%|█████████▉| 514801/518400 [00:00<00:00, 739558.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# define the database uri. In this case we are using a local sqlite database\n",
    "db_uri = \"sqlite:///local_db/assume_db.db\"\n",
    "\n",
    "# create world instance\n",
    "#world = World(database_uri=db_uri, export_csv_path=csv_path)\n",
    "world = World(export_csv_path=csv_path)\n",
    "# load scenario by providing the world instance\n",
    "# the path to the inputs folder and the scenario name (subfolder in inputs)\n",
    "# and the study case name (which config to use for the simulation)\n",
    "load_scenario_folder(\n",
    "    world,\n",
    "    inputs_path=\"inputs\",\n",
    "    scenario=\"example_01\",\n",
    "    study_case=\"hourly_market\",\n",
    ")\n",
    "\n",
    "# run the simulation\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Market Configuration\n",
    "\n",
    "You can easily adjust the market design by changing a few lines in the configuration file. Let's add a new market configuration. Let's say we would like to switch from an hourly market to a day-ahead market with hourly intervals. All we need to do is to change the `opening_frequency` to \"24h\" and `count` to 24. This means, that market opens every 24 hours and each participant needs to submit 24 hourly products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new market config\n",
    "new_market_config = {\n",
    "    \"daily_market\": {\n",
    "        \"start_date\": \"2021-03-01 00:00\",\n",
    "        \"end_date\": \"2021-03-07 00:00\",\n",
    "        \"time_step\": \"1h\",\n",
    "        \"save_frequency_hours\": 24,\n",
    "        \"markets_config\": {\n",
    "            \"EOM\": {\n",
    "                \"operator\": \"EOM_operator\",\n",
    "                \"product_type\": \"energy\",\n",
    "                \"opening_frequency\": \"24h\",\n",
    "                \"opening_duration\": \"1h\",\n",
    "                \"products\": [{\"duration\": \"1h\", \"count\": 24, \"first_delivery\": \"1h\"}],\n",
    "                \"volume_unit\": \"MWh\",\n",
    "                \"price_unit\": \"EUR/MWh\",\n",
    "                \"market_mechanism\": \"pay_as_clear\",\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Update the existing configuration\n",
    "config_data.update(new_market_config)\n",
    "\n",
    "# Save the updated configuration\n",
    "with open(f\"{input_path}/config.yaml\", \"w\") as file:\n",
    "    yaml.dump(config_data, file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Simulation Again\n",
    "\n",
    "With the updated configuration, we can run the simulation for a different study case, in this case for daily_market configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = \"local_db\"  # \"local_db\" or \"timescale\"\n",
    "\n",
    "if data_format == \"local_db\":\n",
    "    db_uri = \"sqlite:///local_db/assume_db.db\"\n",
    "\n",
    "# create world\n",
    "world = World(database_uri=db_uri, export_csv_path=csv_path)\n",
    "\n",
    "# load scenario by providing the world instance\n",
    "# the path to the inputs folder and the scenario name (subfolder in inputs)\n",
    "# and the study case name (which config to use for the simulation)\n",
    "load_scenario_folder(\n",
    "    world,\n",
    "    inputs_path=\"inputs\",\n",
    "    scenario=\"example_01\",\n",
    "    study_case=\"daily_market\",\n",
    ")\n",
    "\n",
    "# run the simulation\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation results\n",
    "\n",
    "After all the simulations are complete, you might want to analyze the results. The results are stored in the database. But they are also written to CSV files at the end of the simulation. The CSV files are stored in the outputs directory, which you are invited to explore. In the next tutorial, we will take a closer look at the simulation results and learn how to visualize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've learned how to automate the setup and execution of simulations in ASSUME using configuration files and input files. This approach is particularly useful for handling large and complex simulations. \n",
    "\n",
    "You are welcome to experiment with different configurations and varying input data. For example, you can try changing the bidding strategy for the power plant units to a more sophisticated strategy, such as a `flexable_eom`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
