
Proposed structure:
1.  Units and units operator receive attribute self.rl_bidder at initialization if strategy is a LearningStrategy or strategy.requires_forecast.
    self.rl_bidder (class RLBidder) contains output dict and forecast
    Initialization of units and units operators remains equal if learning_mode is False/True.

2.  LearningRole responsible to write to rl_params and rl_grad_params, where the "unit" column is substituted by a generic "bidder" column
    LearningRole is activated only if simulation is in learning_mode and handles the recurrent task of writing learning parameters to the database.
    rl_bidders is a list of all units and operators with at least one LearningStrategy.


3.  Bids of portfolio_strategies are always unit-level bids, but rewards are portfolio-level. 
    Strategies receive attribute self.requires_forecast, which is used to initialize units and units_operator

---

`reinforcement_learning/`

    ### NEW! ###

    `RLBidder`: generalizes the concept of a RL-bidder (unit/operator) that needs to store input during training. 
    contains:

        -   `__init__`: defines the outputs defaultdict (as in `BaseUnit.__init__`)
        -   `reset_saved_rl_data`: as in `BaseUnit.reset_saved_rl_data`
        -   adds a `forecaster` obj to the bidder if needed

    ### CHANGED ###

    `learning_role.LearningRole`
        -   add attribute self.rl_bidders (as in `RLUnitsOperator.rl_units`)
        -   add `write_learning_to_output` (as in `RLUnitsOperator`) but write "bidder" instead than "unit" in the `rl_params` table 
        -   add `write_to_learning_role` as in `RLUnitsOperator`, which should use `schedule_recurrent_task` and loop over self.rl_bidders 
        -   modify `write_rl_grad_params_to_output` to write "bidder" instead than "unit" in the `rl_grad_params` table 

    - `tensorboard_logger`
        -   substitute "unit" with "bidder" in the db queries

    - `algorithms.matd3`
        -   substitute strategy.unit_id with strategy.bidder_id

    ### DEPRECATED ###

    `learning_units_operator.RLUnitsOperator`



`scenario/`

    ### CHANGED ###

    -   `loader_csv.setup_world` remove the distinction between `add_rl_unit_operator` for learning and `add_unit_operator` for offline simulation


`world.World`:

    -   `_prepare_bidding_strategies` rename arguments to bidder_id 
    -   `add_learning_strategies_to_learning_role` loop over all rl_bidders, i.e. units and operator with at least one LearningStrategy

    ### DEPRECATED ###

    -   `add_rl_unit_operator`


`common/`

    ### CHANGED ###

    `units_operator.UnitsOperator`:
        -   has attribute self.rl_bidder (`RLBidder`) at `__init__` if one of its `portfolio_strategies` is a `LearningStrategy` or requires_forecast
        -   `formulate_bids` and `formulate_bids_portfolio` should `convert_tensors` if self.bidder is defined (as in `RLUnitsOperator`)
        -   `on_ready` should `schedule_recurrent_task of `write_to_learning_role` if self.bidder is defined (as in `RLUnitsOperator`)
        -   `calculate_portfolio_cashflow_and_reward` calculates unit cashflows and portfolio rewards
        -   `handle_market_feedback` calls `calculate_unit_cashflow_and_reward` if no self.portfolio_strategies, else `calculate_portfolio_cashflow_and_reward`


    `base.BaseUnit`:
        -   has attribute self.rl_bidder (`RLBidder`) at `__init__` if one of its `portfolio_strategies` is a `LearningStrategy` or requires_forecast

    
    `base.BaseStrategy`:
        -   has attribute self.requires_forecast (bool)
    
    `base.LearningStrategy`:
        -   substitute self.unit_id with self.bidder_id

    `WriteOutput`: 
        -   `get_sum_reward` change query to SELECT by "bidder" instead than by "unit"

    `utils.adjust_unit_operator_for_learning`: 











